// Radix sort compute shader, ported from a working Metal implementation.
#pragma kernel SplitPrep
#pragma kernel ScatterElements
#pragma kernel CopyBuffer
#pragma kernel PrefixSum
#pragma kernel PrefixFixup

// Buffers match the C# script
RWStructuredBuffer<uint> inputKeys;
RWStructuredBuffer<uint> inputIndices;
RWStructuredBuffer<uint> outputKeys;
RWStructuredBuffer<uint> outputIndices;
RWStructuredBuffer<uint> eBuffer;
RWStructuredBuffer<uint> fBuffer;
RWStructuredBuffer<uint> auxBuffer;
RWStructuredBuffer<uint> aux2Buffer;

// Parameters
int elementCount;
int currentBit;
int zeroff; // Used by PrefixSum to control exclusive scan output

#define SCAN_BLOCK_SIZE 512

groupshared uint scan_array[SCAN_BLOCK_SIZE * 2];

[numthreads(256, 1, 1)]
void SplitPrep(uint3 id : SV_DispatchThreadID)
{
    int index = (int)id.x;
    if (index >= elementCount) return;
    
    uint mortonCode = inputKeys[index];
    
    // Store 1 for elements with bit 0, and 0 for elements with bit 1.
    eBuffer[index] = ((mortonCode >> (uint)currentBit) & 1) == 0 ? 1 : 0;
}

[numthreads(256, 1, 1)]
void ScatterElements(uint3 id : SV_DispatchThreadID)
{
    int index = (int)id.x;
    if (index >= elementCount) return;

    uint mortonCode = inputKeys[index];
    uint particleIndex = inputIndices[index];

    uint totalFalses = fBuffer[elementCount - 1] + eBuffer[elementCount - 1];

    bool isBitSet = ((mortonCode >> (uint)currentBit) & 1) != 0;

    uint destIndex;
    if (isBitSet)
    {
        uint numOnesBefore = (uint)index - fBuffer[index];
        destIndex = totalFalses + numOnesBefore;
    }
    else
    {
        destIndex = fBuffer[index];
    }

    outputKeys[destIndex] = mortonCode;
    outputIndices[destIndex] = particleIndex;
}

[numthreads(256, 1, 1)]
void CopyBuffer(uint3 id : SV_DispatchThreadID)
{
    int index = (int)id.x;
    if (index >= elementCount) return;
    
    inputKeys[index] = outputKeys[index];
    inputIndices[index] = outputIndices[index];
}

// Ported from the working Metal implementation
[numthreads(512, 1, 1)]
void PrefixSum(uint3 Gid : SV_GroupID, uint3 Gtid : SV_GroupThreadID)
{
    uint threadIdx = Gtid.x;
    uint blockIdx = Gid.x;

    uint t1 = threadIdx + 2 * blockIdx * SCAN_BLOCK_SIZE;
    uint t2 = t1 + SCAN_BLOCK_SIZE;

    // Load into shared memory
    scan_array[threadIdx] = (t1 < elementCount) ? eBuffer[t1] : 0;
    scan_array[threadIdx + SCAN_BLOCK_SIZE] = (t2 < elementCount) ? eBuffer[t2] : 0;
    GroupMemoryBarrierWithGroupSync();

    // Up-sweep (reduction)
    for (uint stride = 1; stride <= SCAN_BLOCK_SIZE; stride <<= 1) {
        uint index = (threadIdx + 1) * stride * 2 - 1;
        if (index < 2 * SCAN_BLOCK_SIZE)
            scan_array[index] += scan_array[index - stride];
        GroupMemoryBarrierWithGroupSync();
    }

    // Down-sweep (broadcast)
    for (uint stride = SCAN_BLOCK_SIZE >> 1; stride > 0; stride >>= 1) {
        uint index = (threadIdx + 1) * stride * 2 - 1;
        if (index + stride < 2 * SCAN_BLOCK_SIZE)
            scan_array[index + stride] += scan_array[index];
        GroupMemoryBarrierWithGroupSync();
    }
    GroupMemoryBarrierWithGroupSync();

    // Write back, converting inclusive scan to exclusive scan using zeroff
    if (t1 + zeroff < elementCount)    fBuffer[t1 + zeroff] = scan_array[threadIdx];
    if (t2 + zeroff < elementCount)    fBuffer[t2 + zeroff] = (threadIdx == (SCAN_BLOCK_SIZE - 1) && zeroff > 0) ? 0 : scan_array[threadIdx + SCAN_BLOCK_SIZE];
    
    if (threadIdx == 0) {
        if (zeroff > 0) fBuffer[0] = 0;
        auxBuffer[blockIdx] = scan_array[2 * SCAN_BLOCK_SIZE - 1];
    }
}

// Ported from the working Metal implementation
[numthreads(512, 1, 1)]
void PrefixFixup(uint3 Gid : SV_GroupID, uint3 Gtid : SV_GroupThreadID)
{
    uint threadIdx = Gtid.x;
    uint blockIdx = Gid.x;
    
    uint t1 = threadIdx + 2 * blockIdx * SCAN_BLOCK_SIZE;
    uint t2 = t1 + SCAN_BLOCK_SIZE;
    uint block_sum = aux2Buffer[blockIdx];
    
    if (t1 < elementCount) fBuffer[t1] += block_sum;
    if (t2 < elementCount) fBuffer[t2] += block_sum;
}