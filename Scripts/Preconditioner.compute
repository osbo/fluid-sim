#pragma kernel ComputeFeatures
#pragma kernel PredictHead
#pragma kernel FusedTransformerLayer

// --- STRUCTS & CONSTANTS ---
struct faceVelocities { float left, right, bottom, top, front, back; };
struct Node {
    float3 position; float3 velocity; faceVelocities velocities;
    float mass; uint layer; uint mortonCode; uint active;
};

// --- BUFFERS ---
StructuredBuffer<Node> nodesBuffer;
StructuredBuffer<uint> neighborsBuffer;
StructuredBuffer<float> diagonalBuffer; // Pre-computed diagonal of Laplacian matrix A

// --- HELPERS ---

// Unpack one uint into two min16floats
min16float2 UnpackFloat16(uint packed)
{
    float v1 = f16tof32(packed & 0xFFFF);
    float v2 = f16tof32(packed >> 16);
    return min16float2((min16float)v1, (min16float)v2);
}

// Helper for random access: fetches the specific weight at 'idx'
min16float UnpackWeight(StructuredBuffer<uint> buf, uint idx)
{
    uint packed = buf[idx >> 1]; // Divide by 2
    min16float2 vals = UnpackFloat16(packed);
    return (idx & 1) ? vals.y : vals.x; // Return low (even) or high (odd)
}

// --- WEIGHT BUFFERS (Change ALL to uint) ---
StructuredBuffer<uint> weightsFeatureProj;
StructuredBuffer<uint> biasFeatureProj;
StructuredBuffer<uint> weightsLayerEmbed;
StructuredBuffer<uint> weightsPosEmbed;

StructuredBuffer<uint> w_attn_in;
StructuredBuffer<uint> b_attn_in;
StructuredBuffer<uint> w_attn_out;
StructuredBuffer<uint> b_attn_out;
StructuredBuffer<uint> w_norm1;
StructuredBuffer<uint> b_norm1;
StructuredBuffer<uint> w_ffn1;
StructuredBuffer<uint> b_ffn1;
StructuredBuffer<uint> w_ffn2;
StructuredBuffer<uint> b_ffn2;
StructuredBuffer<uint> w_norm2;
StructuredBuffer<uint> b_norm2;

StructuredBuffer<uint> w_normOut;
StructuredBuffer<uint> b_normOut;
StructuredBuffer<uint> w_head;
StructuredBuffer<uint> b_head;

// Data Buffers
RWStructuredBuffer<float> tokenBuffer;
RWStructuredBuffer<float> tokenBufferOut;
RWStructuredBuffer<float> bufferQ;          
RWStructuredBuffer<float> bufferK;          
RWStructuredBuffer<float> bufferV;
RWStructuredBuffer<float> bufferAttn;       
RWStructuredBuffer<float> matrixGBuffer;

// Add Global Uniforms
int d_model;
int d_ffn; 

uint numNodes;
uint maxNodes;
int windowSize;  // Window size for attention (default: 256)
int numHeads;    // Number of attention heads (default: 4)
int headOffset;  // Offset for batched head processing

// --- HELPERS ---
float GetDx(uint layer) { return pow(2.0, (float)layer); }

float Gelu(float x) {
    return x * 0.5 * (1.0 + tanh(0.79788 * (x + 0.044715 * x * x * x)));
}

// --- MACRO FOR REDUCTION (32 threads) ---
#define REDUCE_SUM_32(tid, val, s_mem) \
    s_mem[tid] = val; \
    GroupMemoryBarrierWithGroupSync(); \
    if (tid < 16) s_mem[tid] += s_mem[tid + 16]; GroupMemoryBarrierWithGroupSync(); \
    if (tid < 8)  s_mem[tid] += s_mem[tid + 8];  GroupMemoryBarrierWithGroupSync(); \
    if (tid < 4)  s_mem[tid] += s_mem[tid + 4];  GroupMemoryBarrierWithGroupSync(); \
    if (tid < 2)  s_mem[tid] += s_mem[tid + 2];  GroupMemoryBarrierWithGroupSync(); \
    if (tid < 1)  s_mem[tid] += s_mem[tid + 1];  GroupMemoryBarrierWithGroupSync(); \
    val = s_mem[0]; \
    GroupMemoryBarrierWithGroupSync();

// --- KERNEL 1: FEATURES ---
[numthreads(512, 1, 1)] 
void ComputeFeatures(uint3 id : SV_DispatchThreadID)
{
    uint i = id.x;
    if (i >= maxNodes) return;

    // 1. Feature Extraction
    float feats[58];
    // Initialize all features to 0.0
    for(int k=0; k<58; k++) feats[k] = 0.0;
    
    if (i < numNodes) {
        Node n = nodesBuffer[i];
        feats[0] = n.position.x / 1024.0;
        feats[1] = n.position.y / 1024.0;
        feats[2] = n.position.z / 1024.0;

        // Read pre-computed A_diag from buffer (no need to accumulate manually)
        feats[33] = diagonalBuffer[i];

        float dx = GetDx(n.layer);
        int wall_starts[6] = {0, 4, 8, 12, 16, 20};
        for (int f = 0; f < 6; f++) {
            // SoA layout: neighborsBuffer[slot * numNodes + nodeIndex]
            uint w_idx = neighborsBuffer[wall_starts[f] * numNodes + i];
            if (w_idx == numNodes + 1) feats[3 + f] = 1.0; 
            
            bool isCoarseOrSame = false;
            uint slot0_idx = neighborsBuffer[(f * 4) * numNodes + i];
            if (slot0_idx < numNodes) {
                Node n0 = nodesBuffer[slot0_idx];
                if (n0.layer >= n.layer) isCoarseOrSame = true;
            }

            for (int s = 0; s < 4; s++) {
                int local_idx = f * 4 + s;
                if (isCoarseOrSame && s > 0) continue;

                // SoA layout: neighborsBuffer[slot * numNodes + nodeIndex]
                uint n_idx = neighborsBuffer[(f * 4 + s) * numNodes + i];
                if (n_idx == numNodes) feats[9 + local_idx] = 1.0; 
                
                // We still need the loop to compute 'A_off' (indices 34-57)
                // But we removed the 'A_diag +=' accumulator
                float weight = 0.0;
                if (n_idx < numNodes) {
                    Node nb = nodesBuffer[n_idx];
                    float dist = max(0.5 * (dx + GetDx(nb.layer)), 1e-6);
                    float area = (isCoarseOrSame) ? (dx*dx) : (dx*dx*0.25);
                    weight = area / dist;
                    feats[34 + local_idx] = -weight;
                } else if (n_idx == numNodes) { 
                    // Dirichlet boundary contribution to off-diagonals is 0,
                    // so we don't set feats[34+local_idx] (it stays 0.0).
                    // We only needed this branch before for A_diag accumulation.
                    // effectively: do nothing here.
                }
            }
        }
    }

    uint layer = (i < numNodes) ? nodesBuffer[i].layer : 0;
    uint win_pos = i % (uint)windowSize;
    // 2. Linear Projection
    for (int d = 0; d < d_model; d++) {
        float val = (float)UnpackWeight(biasFeatureProj, d);
        for (int f = 0; f < 58; f++) val += feats[f] * (float)UnpackWeight(weightsFeatureProj, f * d_model + d);
        val += (float)UnpackWeight(weightsLayerEmbed, layer * d_model + d);
        val += (float)UnpackWeight(weightsPosEmbed, win_pos * d_model + d);
        tokenBuffer[i * d_model + d] = val;
    }
}


// --- KERNEL 5: PREDICT HEAD (32 Threads) ---
groupshared float s_reduce_head[32];

[numthreads(32, 1, 1)]
void PredictHead(uint3 groupID : SV_GroupID, uint groupIndex : SV_GroupIndex)
{
    uint nodeIdx = groupID.x + (uint)headOffset;
    uint dim = groupIndex; // 0..31
    if (nodeIdx >= numNodes) return;
    
    // REMOVED: if (dim >= (uint)d_model) return;
    
    float val = 0.0;
    if (dim < (uint)d_model) {
        val = tokenBufferOut[nodeIdx * d_model + dim];
    }

    // Norm Out
    float sum = val;
    REDUCE_SUM_32(dim, sum, s_reduce_head);
    float mean = sum / (float)d_model;
    
    float diff = 0.0;
    if (dim < (uint)d_model) diff = val - mean;
    float sqDiff = diff * diff;
    REDUCE_SUM_32(dim, sqDiff, s_reduce_head);
    
    float invStd = rsqrt(sqDiff / (float)d_model + 1e-5);
    
    float x_norm = 0.0;
    if (dim < (uint)d_model) {
        x_norm = diff * invStd * (float)UnpackWeight(w_normOut, dim) + (float)UnpackWeight(b_normOut, dim);
    }
    s_reduce_head[dim] = x_norm;
    GroupMemoryBarrierWithGroupSync();
    
    // Linear d_model -> 25
    if (dim < 25) { 
        float outVal = (float)UnpackWeight(b_head, dim);
        for(int k=0; k<d_model; k++) {
            outVal += s_reduce_head[k] * (float)UnpackWeight(w_head, k * 25 + dim); 
        }
            // SoA layout: matrixGBuffer[dim * numNodes + nodeIdx]
            matrixGBuffer[dim * numNodes + nodeIdx] = outVal; 
        }
}

// --- FusedTransformerLayer - Optimized with Explicit UINT Packing ---
// Window Size: 256 | D_MODEL: 32
// Memory Usage: 32KB (Exactly fits the 32768 byte limit)

#define D_MODEL 32
#define HEADS 4
#define HEAD_DIM 8 // D_MODEL / HEADS
#define WINDOW_SIZE 256

// FIX: Explicitly use uint to force 4-byte storage (2x packed fp16)
// This guarantees usage is 256 * 16 * 4 = 16KB per buffer, 32KB total.
groupshared uint gs_K_packed[WINDOW_SIZE * D_MODEL / 2];
groupshared uint gs_V_packed[WINDOW_SIZE * D_MODEL / 2];

// Helper to pack two floats into one uint
uint PackFloat16(float v1, float v2)
{
    uint i1 = f32tof16(v1);
    uint i2 = f32tof16(v2);
    return i1 | (i2 << 16);
}

[numthreads(WINDOW_SIZE, 1, 1)]
void FusedTransformerLayer(uint3 groupID : SV_GroupID, uint3 groupThreadID : SV_GroupThreadID)
{
    uint localID = groupThreadID.x;
    uint globalID = groupID.x * WINDOW_SIZE + localID;

    // --- PHASE 1: Load Input & Norm 1 ---
    min16float x[D_MODEL];    // Keep for residual
    min16float curr[D_MODEL]; // Working vector

    min16float sum = 0;
    min16float sqSum = 0;
    
    // Check bounds safely
    if (globalID < maxNodes) {
        for (int i = 0; i < D_MODEL; i++) {
            min16float v = (min16float)tokenBuffer[globalID * D_MODEL + i];
            x[i] = v;
            sum += v;
            sqSum += v*v;
        }
    } else {
        for (int i = 0; i < D_MODEL; i++) { 
            x[i] = 0;
            curr[i] = 0; 
        }
    }

    min16float invStd = rsqrt(sqSum/32.0 - (sum/32.0)*(sum/32.0) + 1e-5);
    min16float mean = sum / 32.0;

    // Apply Norm1
    for(int i=0; i<D_MODEL; i++) {
        curr[i] = (x[i] - mean) * invStd * (min16float)UnpackWeight(w_norm1, i) + (min16float)UnpackWeight(b_norm1, i);
    }

    // --- PHASE 2: Q, K, V Projection & Packing ---
    min16float q[D_MODEL];
    
    // 2a. Compute K
    for (int d = 0; d < D_MODEL; d+=2) { 
        // Read packed BIAS
        min16float2 b_vals = UnpackFloat16(b_attn_in[(D_MODEL + d) >> 1]);
        float valK1 = (float)b_vals.x;
        float valK2 = (float)b_vals.y;

        for (int in_d = 0; in_d < D_MODEL; in_d++) {
            float c = (float)curr[in_d];
            // OPTIMIZATION: Read packed WEIGHT
            // Index logic: (in_d * 96 + 32 + d). Stride 96 is even, 32 is even, d is even.
            // So we can divide index by 2 safely.
            uint packedW = w_attn_in[(in_d * 96 + 32 + d) >> 1];
            min16float2 w_vals = UnpackFloat16(packedW);
            
            valK1 += c * (float)w_vals.x;
            valK2 += c * (float)w_vals.y;
        }
        gs_K_packed[localID * (D_MODEL/2) + (d/2)] = PackFloat16(valK1, valK2);
    }

    // 2b. Compute V (Similar optimization)
    for (int d = 0; d < D_MODEL; d+=2) {
        min16float2 b_vals = UnpackFloat16(b_attn_in[(2 * D_MODEL + d) >> 1]);
        float valV1 = (float)b_vals.x;
        float valV2 = (float)b_vals.y;

        for (int in_d = 0; in_d < D_MODEL; in_d++) {
            float c = (float)curr[in_d];
            uint packedW = w_attn_in[(in_d * 96 + 64 + d) >> 1];
            min16float2 w_vals = UnpackFloat16(packedW);
            
            valV1 += c * (float)w_vals.x;
            valV2 += c * (float)w_vals.y;
        }
        gs_V_packed[localID * (D_MODEL/2) + (d/2)] = PackFloat16(valV1, valV2);
    }
    
    // 2c. Compute Q (Register accumulation)
    for (int d = 0; d < D_MODEL; d++) {
        // Here we iterate d by 1, so simpler to use UnpackWeight helper
        min16float valQ = UnpackWeight(b_attn_in, d);
        for (int in_d = 0; in_d < D_MODEL; in_d++) {
            valQ += curr[in_d] * UnpackWeight(w_attn_in, in_d * 96 + d);
        }
        q[d] = valQ;
    }

    GroupMemoryBarrierWithGroupSync();

    // --- PHASE 3: Attention (Unpacking on the fly) ---
    
    // Clear 'curr' to accumulate results
    for(int i=0; i<D_MODEL; i++) curr[i] = 0;
    min16float scale = (min16float)(1.0 / sqrt((float)HEAD_DIM)); 

    [unroll] 
    for (int h = 0; h < HEADS; h++)
    {
        int offset = h * HEAD_DIM;
        min16float m = (min16float)-65504.0;
        min16float d_soft = 0;
        min16float head_res[HEAD_DIM]; 
        for(int z=0; z<HEAD_DIM; z++) head_res[z] = 0;

        [loop] 
        for (int t = 0; t < WINDOW_SIZE; t++)
        {
            min16float score = 0;
            
            // Vectorized Dot Product with Unpacking
            for (int kd = 0; kd < HEAD_DIM; kd+=2) {
                // Read packed uint and unpack to min16float2
                uint packedK = gs_K_packed[t * 16 + (offset + kd)/2];
                min16float2 k_vec = UnpackFloat16(packedK);
                
                score += q[offset + kd] * k_vec.x + q[offset + kd + 1] * k_vec.y;
            }
            score *= scale;

            // Online Softmax
            min16float m_prev = m;
            m = max(m_prev, score);
            min16float e_score = exp(score - m);
            min16float e_prev  = exp(m_prev - m);
            d_soft = d_soft * e_prev + e_score;

            // Accumulate V with Unpacking
            for (int zd = 0; zd < HEAD_DIM; zd+=2) {
                uint packedV = gs_V_packed[t * 16 + (offset + zd)/2];
                min16float2 v_vec = UnpackFloat16(packedV);

                head_res[zd]     = head_res[zd] * e_prev + v_vec.x * e_score;
                head_res[zd + 1] = head_res[zd+1] * e_prev + v_vec.y * e_score;
            }
        }

        // Finalize Head
        min16float inv_d = (min16float)1.0 / (d_soft + (min16float)1e-6);
        for (int z = 0; z < HEAD_DIM; z++) {
            curr[offset + z] = head_res[z] * inv_d;
        }
    }

    // --- PHASE 4: Proj + Residual + Norm 2 ---
    // Reuse 'q' buffer for (x + Proj(curr)) to save registers
    for (int d = 0; d < D_MODEL; d++) {
        min16float val = UnpackWeight(b_attn_out, d);
        for (int k = 0; k < D_MODEL; k++) {
            val += curr[k] * UnpackWeight(w_attn_out, k * D_MODEL + d);
        }
        q[d] = x[d] + val; // Residual 1
    }

    // Norm2 on 'q'
    sum = 0;
    sqSum = 0;
    for(int i=0; i<D_MODEL; i++) { sum+=q[i]; sqSum+=q[i]*q[i]; }
    mean = sum/32.0;
    invStd = rsqrt(sqSum/32.0 - mean*mean + 1e-5);

    // Reuse 'curr' for FFN input
    for(int i=0; i<D_MODEL; i++) {
        curr[i] = (q[i] - mean) * invStd * UnpackWeight(w_norm2, i) + UnpackWeight(b_norm2, i);
    }

    // --- PHASE 5: FFN ---
    for(int i=0; i<D_MODEL; i++) x[i] = UnpackWeight(b_ffn2, i); // Reuse 'x' as output accumulator

    // Hidden layer size is 64 (2 * D_MODEL)
    for(int h=0; h<64; h++) {
        min16float h_val = UnpackWeight(b_ffn1, h);
        for(int in_d=0; in_d<32; in_d++) {
            h_val += curr[in_d] * UnpackWeight(w_ffn1, in_d * 64 + h);
        }
        
        min16float gelu = h_val * 0.5 * (1.0 + tanh(0.79788 * (h_val + 0.044715 * h_val * h_val * h_val)));
        
        for(int out_d=0; out_d<32; out_d++) {
            x[out_d] += gelu * UnpackWeight(w_ffn2, h * 32 + out_d);
        }
    }

    // --- PHASE 6: Write Back ---
    if (globalID < maxNodes) {
        for(int i=0; i<D_MODEL; i++) {
            // q[i] is (x + Attn), x[i] is FFN(norm(q))
            tokenBufferOut[globalID * D_MODEL + i] = (float)(q[i] + x[i]); // Add Residual 2 (FFN)
        }
    }
}